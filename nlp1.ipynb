{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/Users/aydin/Downloads/data.txt\", \"r\", encoding='latin-1')\n",
    "text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'sentence':sent_tokenize(text)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Project Gutenberg EBook of Man to Man, by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or\\nre-use it un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  The Project Gutenberg EBook of Man to Man, by ...\n",
       "1  You may copy it, give it away or\\nre-use it un...\n",
       "2  MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...\n",
       "3  ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...\n",
       "4     MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = stopwords.words('english')\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(data):\n",
    "    text_token = word_tokenize(data.lower())\n",
    "    tokens_without_punc = [w for w in text_token if w.isalpha()]\n",
    "    tokens_without_sw = [t for t in tokens_without_punc if t not in stop_word]\n",
    "    text_cleaned = [lem.lemmatize(t) for t in tokens_without_sw]\n",
    "    return \" \".join(text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence1']=df.sentence.apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Project Gutenberg EBook of Man to Man, by ...</td>\n",
       "      <td>project gutenberg ebook man man jackson gregor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or\\nre-use it un...</td>\n",
       "      <td>may copy give away term project gutenberg lice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...</td>\n",
       "      <td>man man jackson gregory author judith blue lak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...</td>\n",
       "      <td>illustrated shepherd grosset dunlap publisher ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III.</td>\n",
       "      <td>miss blue cloak know beat iii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  The Project Gutenberg EBook of Man to Man, by ...   \n",
       "1  You may copy it, give it away or\\nre-use it un...   \n",
       "2  MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...   \n",
       "3  ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...   \n",
       "4     MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III.   \n",
       "\n",
       "                                           sentence1  \n",
       "0  project gutenberg ebook man man jackson gregor...  \n",
       "1  may copy give away term project gutenberg lice...  \n",
       "2  man man jackson gregory author judith blue lak...  \n",
       "3  illustrated shepherd grosset dunlap publisher ...  \n",
       "4                      miss blue cloak know beat iii  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence2']=df.sentence1.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['sentence1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5974"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count = vectorizer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(X_train_count.toarray(), columns=tf_idf_vek.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abide</th>\n",
       "      <th>abiding</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abreast</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>...</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yonder</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youngest</th>\n",
       "      <th>yourse</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5974 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aback  abandoned  abide  abiding  ability  able  aboard  abreast  abrupt  \\\n",
       "0      0          0      0        0        0     0       0        0       0   \n",
       "1      0          0      0        0        0     0       0        0       0   \n",
       "2      0          0      0        0        0     0       0        0       0   \n",
       "3      0          0      0        0        0     0       0        0       0   \n",
       "4      0          0      0        0        0     0       0        0       0   \n",
       "\n",
       "   abruptly  ...  yielded  yielding  yonder  york  young  youngest  yourse  \\\n",
       "0         0  ...        0         0       0     0      0         0       0   \n",
       "1         0  ...        0         0       0     0      0         0       0   \n",
       "2         0  ...        0         0       0     0      0         0       0   \n",
       "3         0  ...        0         0       0     1      0         0       0   \n",
       "4         0  ...        0         0       0     0      0         0       0   \n",
       "\n",
       "   youth  youthful  zest  \n",
       "0      0         0     0  \n",
       "1      0         0     0  \n",
       "2      0         0     0  \n",
       "3      0         0     0  \n",
       "4      0         0     0  \n",
       "\n",
       "[5 rows x 5974 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vek = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vek.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train__tf_idf = tf_idf_vek.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5560x5974 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 37098 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train__tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(X_train__tf_idf.toarray(), columns=tf_idf_vek.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abide</th>\n",
       "      <th>abiding</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abreast</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>...</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yonder</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youngest</th>\n",
       "      <th>yourse</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5560 rows × 5974 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aback  abandoned  abide  abiding  ability  able  aboard  abreast  \\\n",
       "0       0.0        0.0    0.0      0.0      0.0   0.0     0.0      0.0   \n",
       "1       0.0        0.0    0.0      0.0      0.0   0.0     0.0      0.0   \n",
       "2       0.0        0.0    0.0      0.0      0.0   0.0     0.0      0.0   \n",
       "3       0.0        0.0    0.0      0.0      0.0   0.0     0.0      0.0   \n",
       "4       0.0        0.0    0.0      0.0      0.0   0.0     0.0      0.0   \n",
       "...     ...        ...    ...      ...      ...   ...     ...      ...   \n",
       "5555    0.0        0.0    0.0      0.0      0.0   0.0     0.0      0.0   \n",
       "5556    0.0        0.0    0.0      0.0      0.0   0.0     0.0      0.0   \n",
       "5557    0.0        0.0    0.0      0.0      0.0   0.0     0.0      0.0   \n",
       "5558    0.0        0.0    0.0      0.0      0.0   0.0     0.0      0.0   \n",
       "5559    0.0        0.0    0.0      0.0      0.0   0.0     0.0      0.0   \n",
       "\n",
       "      abrupt  abruptly  ...  yielded  yielding  yonder      york  young  \\\n",
       "0        0.0       0.0  ...      0.0       0.0     0.0  0.000000    0.0   \n",
       "1        0.0       0.0  ...      0.0       0.0     0.0  0.000000    0.0   \n",
       "2        0.0       0.0  ...      0.0       0.0     0.0  0.000000    0.0   \n",
       "3        0.0       0.0  ...      0.0       0.0     0.0  0.242012    0.0   \n",
       "4        0.0       0.0  ...      0.0       0.0     0.0  0.000000    0.0   \n",
       "...      ...       ...  ...      ...       ...     ...       ...    ...   \n",
       "5555     0.0       0.0  ...      0.0       0.0     0.0  0.000000    0.0   \n",
       "5556     0.0       0.0  ...      0.0       0.0     0.0  0.000000    0.0   \n",
       "5557     0.0       0.0  ...      0.0       0.0     0.0  0.000000    0.0   \n",
       "5558     0.0       0.0  ...      0.0       0.0     0.0  0.000000    0.0   \n",
       "5559     0.0       0.0  ...      0.0       0.0     0.0  0.000000    0.0   \n",
       "\n",
       "      youngest  yourse  youth  youthful  zest  \n",
       "0          0.0     0.0    0.0       0.0   0.0  \n",
       "1          0.0     0.0    0.0       0.0   0.0  \n",
       "2          0.0     0.0    0.0       0.0   0.0  \n",
       "3          0.0     0.0    0.0       0.0   0.0  \n",
       "4          0.0     0.0    0.0       0.0   0.0  \n",
       "...        ...     ...    ...       ...   ...  \n",
       "5555       0.0     0.0    0.0       0.0   0.0  \n",
       "5556       0.0     0.0    0.0       0.0   0.0  \n",
       "5557       0.0     0.0    0.0       0.0   0.0  \n",
       "5558       0.0     0.0    0.0       0.0   0.0  \n",
       "5559       0.0     0.0    0.0       0.0   0.0  \n",
       "\n",
       "[5560 rows x 5974 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blenham    128.360228\n",
       "steve      125.768268\n",
       "packard    120.199328\n",
       "terry      107.707614\n",
       "said        96.127514\n",
       "man         92.506243\n",
       "know        83.903305\n",
       "little      66.787684\n",
       "barbee      65.030515\n",
       "old         63.422005\n",
       "come        55.026520\n",
       "eye         54.913753\n",
       "back        53.491803\n",
       "one         51.743381\n",
       "got         51.479906\n",
       "way         50.261725\n",
       "go          49.909066\n",
       "like        47.275950\n",
       "get         46.055100\n",
       "royce       45.663666\n",
       "hand        45.249600\n",
       "time        45.128141\n",
       "temple      44.649934\n",
       "would       44.461495\n",
       "bill        44.366097\n",
       "asked       41.805647\n",
       "want        41.014388\n",
       "right       40.241971\n",
       "came        39.659420\n",
       "say         38.473603\n",
       "going       38.259565\n",
       "men         37.937675\n",
       "see         35.686267\n",
       "cried       35.431432\n",
       "wood        35.350127\n",
       "two         35.029899\n",
       "guy         34.892769\n",
       "well        34.755700\n",
       "went        34.096359\n",
       "thing       33.920778\n",
       "look        33.361277\n",
       "could       32.603259\n",
       "let         32.599056\n",
       "good        31.611120\n",
       "big         30.354180\n",
       "ten         30.157480\n",
       "head        29.751713\n",
       "upon        29.287107\n",
       "horse       29.177197\n",
       "word        27.622725\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum().sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "steve      542\n",
       "packard    541\n",
       "blenham    524\n",
       "man        445\n",
       "terry      409\n",
       "said       307\n",
       "little     291\n",
       "old        284\n",
       "eye        261\n",
       "know       224\n",
       "one        219\n",
       "barbee     213\n",
       "back       210\n",
       "way        194\n",
       "hand       193\n",
       "would      185\n",
       "time       179\n",
       "like       174\n",
       "come       170\n",
       "temple     168\n",
       "came       159\n",
       "got        156\n",
       "men        152\n",
       "royce      150\n",
       "go         145\n",
       "upon       141\n",
       "two        137\n",
       "could      128\n",
       "went       127\n",
       "get        126\n",
       "bill       125\n",
       "big        124\n",
       "right      122\n",
       "wood       116\n",
       "thing      114\n",
       "head       113\n",
       "horse      112\n",
       "ranch      111\n",
       "face       111\n",
       "going      108\n",
       "ten        107\n",
       "made       106\n",
       "see        103\n",
       "guy        102\n",
       "good       101\n",
       "work       101\n",
       "look       100\n",
       "across      98\n",
       "want        96\n",
       "long        96\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum().sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
