{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aw04Z9dIASCz"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9jfMvQRASCz"
   },
   "source": [
    "# WELCOME!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEckIoqPASCz"
   },
   "source": [
    "Welcome to \"***Tree Types Prediction Project***\". This is the second medium project of ***Machine Learning*** course.\n",
    "\n",
    "In this project, you must perform EDA processes for implementing predictive models. Handling outliers, domain knowledge and feature engineering (using ***sqlite3*** library) will be challenges. \n",
    "\n",
    "Also, this project aims to improve your ability to implement algorithms for ***Multi-Class Classification***. Thus, you will have the opportunity to implement many algorithms commonly used for Multi-Class Classification problems.\n",
    "\n",
    "Before diving into the project, please take a look at the determines and tasks.\n",
    "\n",
    "- ***NOTE:*** *This project assumes that you already know the basics of coding in Python. You should also be familiar with the theory behind classification models and scikit-learn module as well as Machine Learning before you begin.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWUbnCOHASCz"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxA4M_USASCz"
   },
   "source": [
    "# #Determines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxyFkA5PASCz"
   },
   "source": [
    "Dataset contains tree observations from four areas of one national forest district. This dataset includes information on tree type, shadow coverage, distance to nearby landmarks, soil type, and local topography. The goal of the project is to build a model that predicts what types of trees grow in an area.\n",
    "***The Forest Dataset*** contains approximately 600 thousand lines, also you can easily find many information about it on the web (especially Kaggle).\n",
    "\n",
    "---\n",
    "\n",
    "To achieve high prediction success, you must understand the data well and develop different approaches that can affect the dependent variable.\n",
    "\n",
    "Firstly, try to understand the dataset column by column using pandas module. Do research within the scope of domain (forest, trees) knowledge on the internet to get to know the data set in the fastest way. \n",
    "\n",
    "You should implement cleaning, handling with outliers and missing values using Pandas, NumPy and other required modules for the best result in modeling. You should do Feature Engineering using SQLite local database. \n",
    "\n",
    "At this point, in order to improve your skills of using SQL with Python, you are asked to perform feature engineering operations using *sqlite3* library in Python.\n",
    "\n",
    "After that, your final dataset with the new variables you have created will be ready for model building. You will implement ***Support Vector Machine, XGBoost, Random Forest, Desicion Tree*** and ***K-Nearest Neighbors (KNN)*** algorithms. Also, evaluate the success of your models with appropriate performance metrics and visualize them using ***Yellowbrick, Seaborn*** or ***Matplotlib*** modules.\n",
    "\n",
    "At the end of the project, create a chart comparing the performance of all models and choose the most successful model.\n",
    "\n",
    "- ***NOTE:*** *Evaluate your models knowing that this is [imbalanced data](https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb). This is not the primary goal of the project, but you can study solve the class [imbalance problem](https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28) if you want.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdOyfC8jASCz"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3DXc1w6ASCz"
   },
   "source": [
    "# #Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UykgYK5-ASCz"
   },
   "source": [
    "#### 1. Exploratory Data Analysis (EDA)\n",
    "- Import Libraries, Load Dataset, Exploring Data\n",
    "\n",
    "    *i. Import Libraries*\n",
    "    \n",
    "    *ii. Load Dataset*\n",
    "    \n",
    "    *iii. Explore Data*\n",
    "\n",
    "#### 2.  Data Cleaning\n",
    "- Detect Missing Values and Outliers \n",
    "\n",
    "    *i. Missing Value Detection*\n",
    "    \n",
    "    *ii. Outlier Detection*\n",
    "    \n",
    "- Deal with Outliers\n",
    "    \n",
    "    *i. Visualize Zscore Tresholds (how many times IQR) by Continuous Variables*\n",
    "    \n",
    "    *ii. Drop Outliers*\n",
    "\n",
    "\n",
    "#### 3. Feature Engineering with sqlite3 Module\n",
    "\n",
    "\n",
    "#### 4. Prediction (Multi-class Classification)\n",
    "- Import libraries\n",
    "- Data Preprocessing\n",
    "- Implement KNN Classifer\n",
    "- Implement Decision Tree Classifier\n",
    "- Implement Random Forest Classifer\n",
    "- Implement XGBoost Classifer\n",
    "- Implement SVM Classifer\n",
    "- Compare The Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "934v5Lm0ASCz"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70sZDrv1ASCz"
   },
   "source": [
    "## 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AZiiwrgri2o"
   },
   "source": [
    "### Import Libraries, Load Dataset, Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhoTMDVLASCz"
   },
   "source": [
    "#### *i. Import Libraries*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKbc1uEQASCz"
   },
   "source": [
    "Besides Numpy and Pandas, you need to import the necessary modules for data visualization, data preprocessing, Model building and tuning.\n",
    "\n",
    "*Note: Check out the course materials.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0ThMJSTCASCz"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUxd8117ASCz"
   },
   "source": [
    "#### *ii. Load Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nO4IbFeNASC0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('covtype.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8W545bnASC0"
   },
   "source": [
    "#### *iii. Explore Data*\n",
    "- Focus on numerical and categorical data\n",
    "- Detect Number of Unique values of each column\n",
    "- Focus on Target Variable (Cover_Type)\n",
    " - Detect relationships and correlations between independent variables and target variable.\n",
    " - It may be nice to visualize the class frequencies of the target variable.\n",
    "- Detect relationships and correlations between independent variables. (You can prefer to keep only one of the highly correlated continuous variables.)\n",
    "- Consider dropping features that contain little data or that you think will not contribute to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BVE7_TsoASC0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 581012 entries, 0 to 581011\n",
      "Data columns (total 55 columns):\n",
      " #   Column                              Non-Null Count   Dtype\n",
      "---  ------                              --------------   -----\n",
      " 0   Elevation                           581012 non-null  int64\n",
      " 1   Aspect                              581012 non-null  int64\n",
      " 2   Slope                               581012 non-null  int64\n",
      " 3   Horizontal_Distance_To_Hydrology    581012 non-null  int64\n",
      " 4   Vertical_Distance_To_Hydrology      581012 non-null  int64\n",
      " 5   Horizontal_Distance_To_Roadways     581012 non-null  int64\n",
      " 6   Hillshade_9am                       581012 non-null  int64\n",
      " 7   Hillshade_Noon                      581012 non-null  int64\n",
      " 8   Hillshade_3pm                       581012 non-null  int64\n",
      " 9   Horizontal_Distance_To_Fire_Points  581012 non-null  int64\n",
      " 10  Wilderness_Area1                    581012 non-null  int64\n",
      " 11  Wilderness_Area2                    581012 non-null  int64\n",
      " 12  Wilderness_Area3                    581012 non-null  int64\n",
      " 13  Wilderness_Area4                    581012 non-null  int64\n",
      " 14  Soil_Type1                          581012 non-null  int64\n",
      " 15  Soil_Type2                          581012 non-null  int64\n",
      " 16  Soil_Type3                          581012 non-null  int64\n",
      " 17  Soil_Type4                          581012 non-null  int64\n",
      " 18  Soil_Type5                          581012 non-null  int64\n",
      " 19  Soil_Type6                          581012 non-null  int64\n",
      " 20  Soil_Type7                          581012 non-null  int64\n",
      " 21  Soil_Type8                          581012 non-null  int64\n",
      " 22  Soil_Type9                          581012 non-null  int64\n",
      " 23  Soil_Type10                         581012 non-null  int64\n",
      " 24  Soil_Type11                         581012 non-null  int64\n",
      " 25  Soil_Type12                         581012 non-null  int64\n",
      " 26  Soil_Type13                         581012 non-null  int64\n",
      " 27  Soil_Type14                         581012 non-null  int64\n",
      " 28  Soil_Type15                         581012 non-null  int64\n",
      " 29  Soil_Type16                         581012 non-null  int64\n",
      " 30  Soil_Type17                         581012 non-null  int64\n",
      " 31  Soil_Type18                         581012 non-null  int64\n",
      " 32  Soil_Type19                         581012 non-null  int64\n",
      " 33  Soil_Type20                         581012 non-null  int64\n",
      " 34  Soil_Type21                         581012 non-null  int64\n",
      " 35  Soil_Type22                         581012 non-null  int64\n",
      " 36  Soil_Type23                         581012 non-null  int64\n",
      " 37  Soil_Type24                         581012 non-null  int64\n",
      " 38  Soil_Type25                         581012 non-null  int64\n",
      " 39  Soil_Type26                         581012 non-null  int64\n",
      " 40  Soil_Type27                         581012 non-null  int64\n",
      " 41  Soil_Type28                         581012 non-null  int64\n",
      " 42  Soil_Type29                         581012 non-null  int64\n",
      " 43  Soil_Type30                         581012 non-null  int64\n",
      " 44  Soil_Type31                         581012 non-null  int64\n",
      " 45  Soil_Type32                         581012 non-null  int64\n",
      " 46  Soil_Type33                         581012 non-null  int64\n",
      " 47  Soil_Type34                         581012 non-null  int64\n",
      " 48  Soil_Type35                         581012 non-null  int64\n",
      " 49  Soil_Type36                         581012 non-null  int64\n",
      " 50  Soil_Type37                         581012 non-null  int64\n",
      " 51  Soil_Type38                         581012 non-null  int64\n",
      " 52  Soil_Type39                         581012 non-null  int64\n",
      " 53  Soil_Type40                         581012 non-null  int64\n",
      " 54  Cover_Type                          581012 non-null  int64\n",
      "dtypes: int64(55)\n",
      "memory usage: 243.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           5  \n",
       "1            0            0           5  \n",
       "2            0            0           2  \n",
       "3            0            0           2  \n",
       "4            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQeP_Dhtri3v"
   },
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdwJqW45ASC0"
   },
   "source": [
    "## 2.  Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h95eEjnEASC0"
   },
   "source": [
    "### Detect Missing Values and Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNvbnTdnASC0"
   },
   "source": [
    "#### *i. Missing Value Detection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkLpnVcvASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdTLXhWeASC0"
   },
   "source": [
    "#### *ii. Outlier Detection*\n",
    "\n",
    "The columns which have continuous value should be examined in terms of [outliers](https://datascience.foundation/sciencewhitepaper/knowing-all-about-outliers-in-machine-learning) (Watch out for columns that look like continuous but not continuous!). Some algorithms are [sensitive to outliers](https://arsrinevetha.medium.com/ml-algorithms-sensitivity-towards-outliers-f3862a13c94d), but some algorithms can tolerate them. You can decide to outlier detection according to the algorithm you will use.\n",
    "- You can check the outliers shape of continous features with respect to the target (Cover_Type) classes.\n",
    "- You can check how many outliers are there of each continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cj4fc_jASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ax0-S9b6ri3I"
   },
   "source": [
    "### Deal with Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQPOenOmri3O"
   },
   "source": [
    "#### *i. Visualize Zscore Tresholds (how many times IQR) by Continuous Variables*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkpePUCYASC0"
   },
   "source": [
    "There are many different methods for outliers. You can use IQR values used as standard to deal with outliers, or you can define two functions to help you understand the outliers and how you can deal with them.\n",
    "- Two functions given as extra for outlier detection in *EDA Project (Outo Scout)* are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28KUmwCLri3L",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def outlier_zscore(df, col, min_z=1, max_z = 5, step = 0.1, print_list = False):\n",
    "    z_scores = zscore(df[col].dropna())\n",
    "    threshold_list = []\n",
    "    for threshold in np.arange(min_z, max_z, step):\n",
    "        threshold_list.append((threshold, len(np.where(z_scores > threshold)[0])))\n",
    "        df_outlier = pd.DataFrame(threshold_list, columns = ['threshold', 'outlier_count'])\n",
    "        df_outlier['pct'] = (df_outlier.outlier_count - df_outlier.outlier_count.shift(-1))/df_outlier.outlier_count*100\n",
    "    plt.plot(df_outlier.threshold, df_outlier.outlier_count)\n",
    "    best_treshold = round(df_outlier.iloc[df_outlier.pct.argmax(), 0],2)\n",
    "    outlier_limit = int(df[col].dropna().mean() + (df[col].dropna().std()) * df_outlier.iloc[df_outlier.pct.argmax(), 0])\n",
    "    percentile_threshold = stats.percentileofscore(df[col].dropna(), outlier_limit)\n",
    "    plt.vlines(best_treshold, 0, df_outlier.outlier_count.max(), \n",
    "               colors=\"r\", ls = \":\"\n",
    "              )\n",
    "    plt.annotate(\"Zscore : {}\\nValue : {}\\nPercentile : {}\".format(best_treshold, outlier_limit, \n",
    "                                                                   (np.round(percentile_threshold, 3), \n",
    "                                                                    np.round(100-percentile_threshold, 3))), \n",
    "                 (best_treshold, df_outlier.outlier_count.max()/2))\n",
    "    #plt.show()\n",
    "    if print_list:\n",
    "        print(df_outlier)\n",
    "    return (plt, df_outlier, best_treshold, outlier_limit, percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uu2x64KDri3N",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def outlier_inspect(df, col, min_z=1, max_z = 5, step = 0.5, max_hist = None, bins = 50):\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    fig.suptitle(col, fontsize=16)\n",
    "    plt.subplot(1,3,1)\n",
    "    if max_hist == None:\n",
    "        sns.distplot(df[col], kde=False, bins = 50)\n",
    "    else :\n",
    "        sns.distplot(df[df[col]<=max_hist][col], kde=False, bins = 50)\n",
    "    plt.subplot(1,3,2)\n",
    "    sns.boxplot(df[col])\n",
    "    plt.subplot(1,3,3)\n",
    "    z_score_inspect = outlier_zscore(df, col, min_z=min_z, max_z = max_z, step = step)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3DOlPiIASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfVCLwHlASC0"
   },
   "source": [
    "#### *ii. Drop Outliers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1e8ZBCvASC0"
   },
   "source": [
    "You can define another function to detect outliers in accordance with the ``zscore`` (how many times IQR) value you choose according to the result from the previous functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCEpJdxWASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjDFWFcgASC0"
   },
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzffSKptri3v"
   },
   "source": [
    "## 3. Feature Engineering with *sqlite3* Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJy4l8xqASC0"
   },
   "source": [
    "Feature engineering is an optional process to increase the predictive success of the model. The effort you put in should be worth increasing success. So you can develop your own feature engineering approach.\n",
    "\n",
    "Note that, after seeing the result of the models, there may be a possibility of making minor changes to the features in the modeling phase.\n",
    "\n",
    "You are requested to do feature engineering operations with SQL. There are two ways to do this:\n",
    "1. After moving the final version of your data set to ***SQLite Browser*** and performing feature engineering operations there, you can convert the resulting data set to dataframe format and use it again in python.\n",
    "2. In Python, you can create a database and table with your data set by using the functions of the sqlite3 library, after performing feature engineering with SQL, you can convert the resulting data set to a dataframe.\n",
    "\n",
    "In this case, we will illustrate the second method.\n",
    "\n",
    "Follow the steps below to do feature engineering with the [sqlite3](https://docs.python.org/3/library/sqlite3.html) library:\n",
    " 1. Import *sqlite3* library\n",
    " 2. Create a sqlite database (``\"tree_database\"``) and transferring dataframe(``tree1``) from python into database table (``covtype2``)\n",
    "  - You can use *connect(), to_sql() and read_sql_query()* functions.\n",
    " 3. Assign SQL codes for feature engineering to an object. (produce or transform new columns, get rid of unnecassary columns, make the dataset ready to model)\n",
    " 4. Transform final version of SQL table to dataframe.\n",
    " \n",
    "Finally, you can save the final version of your data as csv for use in your models and work on a different notebook. On the other hand, you can continue to work on this notebook with the last dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yP5LibfOASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45zRLFdDASC0"
   },
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ylwp86BnIbfD"
   },
   "source": [
    "## 4. Prediction (Multi-class Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hmyNTpmASC0"
   },
   "source": [
    "If you have done, use your data set resulting from Feature Engineering task. If you haven't done Feature Engineering, use the latest version of your data set.\n",
    "In this section, you have two main tasks that apply to each algorithm:\n",
    "1. Model Building and Prediction\n",
    "\n",
    " - XGBoost (Use ``XGBClassifier`` model from``xgboost`` module)\n",
    " - SVM (Use ``LinearSVC`` model from``sklearn.svm`` module)\n",
    " - Decision Tree (Use ``DecisionTreeClassifier`` model from ``sklearn.tree`` module)\n",
    " - KNN (Use ``KNeighborsClassifier`` model from ``sklearn.neighbors`` module)\n",
    " - Random Forest (Use ``RandomForestClassifier`` model from ``sklearn.ensemble`` module) \n",
    " \n",
    "\n",
    "2. Visualizing the Result\n",
    "\n",
    "- Use [yellowbrick](https://www.scikit-yb.org/en/latest/), [seaborn](https://seaborn.pydata.org/tutorial/regression.html) or [matplotlib](https://matplotlib.org/) modules to visualize the model results.\n",
    "\n",
    "- Show three plots for the results:\n",
    " - Class Prediction Error Bar Plot\n",
    " - Confusion Matrix\n",
    " - Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bKNukyEASC0"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44t5jjukASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-HeuK9FIbfJ"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W22WncJ9ASC0"
   },
   "source": [
    "- Drop target variable\n",
    "- Train-Test Split\n",
    "\n",
    "*Note: You can use the train and test data generated here for all algorithms.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFD5URwnASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFcrnBI3ASC0"
   },
   "source": [
    "### Implement KNeighborsClassifer\n",
    "\n",
    "The first and most important step for the [KNN](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/) algorithm is to determine the optimal k (number of neighbors). \n",
    "\n",
    "Build different models with k values in the range you specify. You can observe the change of train and test accuracy values according to different k values using a plot. The point at which train accuracy and test accuracy values begin to run parallel is the optimal k value. Then set up your final KNN model with the optimal k value you determined and calculate accuracy.\n",
    "\n",
    "- Import the modul\n",
    "- Fit the model \n",
    "- Predict the test set\n",
    "- Visualize the result\n",
    "- Evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbZ_N3BDASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2bAc81fASC0"
   },
   "source": [
    "### Implement Decision Tree Classifier\n",
    "- Import the modul \n",
    "- Fit the model \n",
    "- Predict the test set\n",
    "- Visualize and evaluate the result (use yellowbrick module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C871JJvXASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-Hv3OSrASC0"
   },
   "source": [
    "### Implement Random Forest Classifier\n",
    "- Import the modul \n",
    "- Fit the model \n",
    "- Predict the test set\n",
    "- Visualize and evaluate the result (use yellowbrick module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZER2XJrrASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eI7Zd8TLIbfK"
   },
   "source": [
    "### Implement XGBoost Classifer\n",
    "- Import the modul \n",
    "- Fit the model \n",
    "- Predict the test set\n",
    "- Visualize and evaluate the result (use yellowbrick module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMc5EJsiASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOisMsLIASC0"
   },
   "source": [
    "### Implement Support Vector Machine\n",
    "- Import the modul \n",
    "- Fit the model \n",
    "- Predict the test set\n",
    "- Visualize and evaluate the result (use yellowbrick module)\n",
    "\n",
    "*Note: You probably won't get a successful result. You may need to make some changes to the model or data. This may be a topic worth investigating, you decide.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "202mKGwcASC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67xA-4xdASC0"
   },
   "source": [
    "### Compare The Models\n",
    "\n",
    "So far, you have created a multi-classifier model with 5 different algorithms and made predictions. You can observe the performance of the models together with a barplot of your choice.\n",
    "\n",
    "- Which algorithm did you achieve the highest prediction performance with? \n",
    "- What could be the factors that cause this? What are the principles of the most successful algorithm and its differences from other algorithms? \n",
    "\n",
    "In contrast;\n",
    "\n",
    "- Which algorithm did you achieve the lowest prediction performance with? \n",
    "- What could be the factors that cause this? What are the principles of the most successful algorithm and its differences from other algorithms? \n",
    "\n",
    "The answers you will look for to these questions will increase your gains from Machine Learning course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeNjYhBaB2YH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6wYrrIuASC0"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tree_Types_Prediction_Student_V1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
